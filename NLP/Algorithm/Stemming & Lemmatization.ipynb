{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the nltk package\n",
    "import nltk\n",
    "#call the nltk downloader\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer\n",
      "cat\n",
      "troubl\n",
      "troubl\n",
      "troubl\n",
      "Lancaster Stemmer\n",
      "cat\n",
      "troubl\n",
      "troubl\n",
      "troubl\n"
     ]
    }
   ],
   "source": [
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "#proide a word to be stemmed\n",
    "print(\"Porter Stemmer\")\n",
    "print(porter.stem(\"cats\"))\n",
    "print(porter.stem(\"trouble\"))\n",
    "print(porter.stem(\"troubling\"))\n",
    "print(porter.stem(\"troubled\"))\n",
    "print(\"Lancaster Stemmer\")\n",
    "print(lancaster.stem(\"cats\"))\n",
    "print(lancaster.stem(\"trouble\"))\n",
    "print(lancaster.stem(\"troubling\"))\n",
    "print(lancaster.stem(\"troubled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Porter Stemmer      Lancaster Stemmer   \n",
      "friend              friend              friend              \n",
      "friendship          friendship          friend              \n",
      "friends             friend              friend              \n",
      "friendships         friendship          friend              \n",
      "stabil              stabil              stabl               \n",
      "destabilize         destabil            dest                \n",
      "misunderstanding    misunderstand       misunderstand       \n",
      "railroad            railroad            railroad            \n",
      "moonlight           moonlight           moonlight           \n",
      "football            footbal             footbal             \n"
     ]
    }
   ],
   "source": [
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\", \"Lancaster Stemmer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,porter.stem(word),lancaster.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\"\n",
    "porter.stem(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python are veri intellig and work veri pythonli and now they are python their way to success . \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def stemSentence(sentence):\n",
    "    token_words = word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "x = stemSentence(sentence)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from data in various forms, both structured and unstructured,[1][2] similar to data mining. \\\\nData science is a \"concept to unify statistics, data analysis, machine learning and their related methods\" in order to \"understand and analyze actual phenomena\" with data.[3] It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science. \\\\nTuring award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\\\\nIn 2012, when Harvard Business Review called it \"The Sexiest Job of the 21st Century\",[6] the term \"data science\" became a buzzword. It is now often used interchangeably with earlier concepts like business analytics,[7] business intelligence, predictive modeling, and statistics. In many cases, earlier approaches and solutions are now simply rebranded as \"data science\" to be more attractive, which can cause the term to become \"dilute[d] beyond usefulness.\"While many university programs now offer a data science degree, there exists no consensus on a definition or suitable curriculum contents.To its discredit, however, many data-science and big-data projects fail to deliver useful results, often as a result of poor management and utilization of resources.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"Stemming and Lemmatization\\data-science-wiki.txt\")\n",
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from data in various forms, both structured and unstructured,[1][2] similar to data mining. \\\\nData science is a \"concept to unify statistics, data analysis, machine learning and their related methods\" in order to \"understand and analyze actual phenomena\" with data.[3] It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science. \\\\nTuring award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\\\\nIn 2012, when Harvard Business Review called it \"The Sexiest Job of the 21st Century\",[6] the term \"data science\" became a buzzword. It is now often used interchangeably with earlier concepts like business analytics,[7] business intelligence, predictive modeling, and statistics. In many cases, earlier approaches and solutions are now simply rebranded as \"data science\" to be more attractive, which can cause the term to become \"dilute[d] beyond usefulness.\"While many university programs now offer a data science degree, there exists no consensus on a definition or suitable curriculum contents.To its discredit, however, many data-science and big-data projects fail to deliver useful results, often as a result of poor management and utilization of resources.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=open(\"Stemming and Lemmatization\\data-science-wiki.txt\")\n",
    "my_lines_list = file.readlines()\n",
    "my_lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from data in various forms, both structured and unstructured,[1][2] similar to data mining. \\nData science is a \"concept to unify statistics, data analysis, machine learning and their related methods\" in order to \"understand and analyze actual phenomena\" with data.[3] It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science. \\nTuring award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\\nIn 2012, when Harvard Business Review called it \"The Sexiest Job of the 21st Century\",[6] the term \"data science\" became a buzzword. It is now often used interchangeably with earlier concepts like business analytics,[7] business intelligence, predictive modeling, and statistics. In many cases, earlier approaches and solutions are now simply rebranded as \"data science\" to be more attractive, which can cause the term to become \"dilute[d] beyond usefulness.\"While many university programs now offer a data science degree, there exists no consensus on a definition or suitable curriculum contents.To its discredit, however, many data-science and big-data projects fail to deliver useful results, often as a result of poor management and utilization of resources.\n",
      "Stemmed sentence\n",
      "data scienc is an interdisciplinari field that use scientif method , process , algorithm and system to extract knowledg and insight from data in variou form , both structur and unstructur , [ 1 ] [ 2 ] similar to data mine . \\ndata scienc is a `` concept to unifi statist , data analysi , machin learn and their relat method '' in order to `` understand and analyz actual phenomena '' with data . [ 3 ] It employ techniqu and theori drawn from mani field within the context of mathemat , statist , inform scienc , and comput scienc . \\nture award winner jim gray imagin data scienc as a `` fourth paradigm '' of scienc ( empir , theoret , comput and now data-driven ) and assert that `` everyth about scienc is chang becaus of the impact of inform technolog '' and the data deluge.\\nin 2012 , when harvard busi review call it `` the sexiest job of the 21st centuri '' , [ 6 ] the term `` data scienc '' becam a buzzword . It is now often use interchang with earlier concept like busi analyt , [ 7 ] busi intellig , predict model , and statist . In mani case , earlier approach and solut are now simpli rebrand as `` data scienc '' to be more attract , which can caus the term to becom `` dilut [ d ] beyond use . `` while mani univers program now offer a data scienc degre , there exist no consensu on a definit or suitabl curriculum contents.to it discredit , howev , mani data-sci and big-data project fail to deliv use result , often as a result of poor manag and util of resourc . \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "print(my_lines_list[0])\n",
    "print(\"Stemmed sentence\")\n",
    "x = stemSentence(my_lines_list[0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_file=open(\"Stemming and Lemmatization\\stem-data-science-wiki.txt\",mode=\"a+\", encoding=\"utf-8\")\n",
    "for line in my_lines_list:\n",
    "    stem_sentence = stemSentence(line)\n",
    "    stem_file.write(stem_sentence)\n",
    "    \n",
    "stem_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to C:\\Users\\DIGI\n",
      "[nltk_data]     KUTIR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')',\n",
       " 'The',\n",
       " 'pale',\n",
       " 'Usher',\n",
       " '--',\n",
       " 'threadbare',\n",
       " 'in',\n",
       " 'coat',\n",
       " ',',\n",
       " 'heart',\n",
       " ',',\n",
       " 'body',\n",
       " ',',\n",
       " 'and',\n",
       " 'brain',\n",
       " ';',\n",
       " 'I',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'ever',\n",
       " 'dusting',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicons',\n",
       " 'and',\n",
       " 'grammars',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'queer',\n",
       " 'handkerchief',\n",
       " ',',\n",
       " 'mockingly',\n",
       " 'embellished',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'gay',\n",
       " 'flags',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'known',\n",
       " 'nations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'He',\n",
       " 'loved',\n",
       " 'to',\n",
       " 'dust',\n",
       " 'his',\n",
       " 'old',\n",
       " 'grammars',\n",
       " ';',\n",
       " 'it',\n",
       " 'somehow',\n",
       " 'mildly',\n",
       " 'reminded',\n",
       " 'him',\n",
       " 'of',\n",
       " 'his',\n",
       " 'mortality',\n",
       " '.',\n",
       " '\"',\n",
       " 'While',\n",
       " 'you',\n",
       " 'take',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'to',\n",
       " 'school',\n",
       " 'others',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'teach',\n",
       " 'them',\n",
       " 'by',\n",
       " 'what',\n",
       " 'name',\n",
       " 'a',\n",
       " 'whale',\n",
       " '-',\n",
       " 'fish',\n",
       " 'is',\n",
       " 'to',\n",
       " 'be',\n",
       " 'called',\n",
       " 'in',\n",
       " 'our',\n",
       " 'tongue',\n",
       " 'leaving',\n",
       " 'out',\n",
       " ',',\n",
       " 'through',\n",
       " 'ignorance',\n",
       " ',',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'H',\n",
       " ',',\n",
       " 'which',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'maketh',\n",
       " 'the',\n",
       " 'signification',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " ',',\n",
       " 'you',\n",
       " 'deliver',\n",
       " 'that',\n",
       " 'which',\n",
       " 'is',\n",
       " 'not',\n",
       " 'true',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HACKLUYT',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'Sw',\n",
       " '.',\n",
       " 'and',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVAL',\n",
       " '.',\n",
       " 'This',\n",
       " 'animal',\n",
       " 'is',\n",
       " 'named',\n",
       " 'from',\n",
       " 'roundness',\n",
       " 'or',\n",
       " 'rolling',\n",
       " ';',\n",
       " 'for',\n",
       " 'in',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVALT',\n",
       " 'is',\n",
       " 'arched',\n",
       " 'or',\n",
       " 'vaulted',\n",
       " '.\"',\n",
       " '--',\n",
       " 'WEBSTER',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'It',\n",
       " 'is',\n",
       " 'more',\n",
       " 'immediately',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Dut',\n",
       " '.',\n",
       " 'and',\n",
       " 'Ger',\n",
       " '.',\n",
       " 'WALLEN',\n",
       " ';',\n",
       " 'A',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " 'WALW',\n",
       " '-',\n",
       " 'IAN',\n",
       " ',',\n",
       " 'to',\n",
       " 'roll',\n",
       " ',',\n",
       " 'to',\n",
       " 'wallow',\n",
       " '.\"',\n",
       " '--',\n",
       " 'RICHARDSON',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " ',',\n",
       " 'GREEK',\n",
       " '.',\n",
       " 'CETUS',\n",
       " ',',\n",
       " 'LATIN',\n",
       " '.',\n",
       " 'WHOEL',\n",
       " ',',\n",
       " 'ANGLO',\n",
       " '-',\n",
       " 'SAXON',\n",
       " '.',\n",
       " 'HVALT',\n",
       " ',',\n",
       " 'DANISH',\n",
       " '.',\n",
       " 'WAL',\n",
       " ',',\n",
       " 'DUTCH',\n",
       " '.',\n",
       " 'HWAL',\n",
       " ',',\n",
       " 'SWEDISH',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ICELANDIC',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ENGLISH',\n",
       " '.',\n",
       " 'BALEINE',\n",
       " ',',\n",
       " 'FRENCH',\n",
       " '.',\n",
       " 'BALLENA',\n",
       " ',',\n",
       " 'SPANISH',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'FEGEE',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'ERROMANGOAN',\n",
       " '.',\n",
       " 'EXTRACTS',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Sub',\n",
       " '-',\n",
       " 'Sub',\n",
       " '-',\n",
       " 'Librarian',\n",
       " ').',\n",
       " 'It',\n",
       " 'will',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'that',\n",
       " 'this',\n",
       " 'mere',\n",
       " 'painstaking',\n",
       " 'burrower',\n",
       " 'and',\n",
       " 'grub',\n",
       " '-',\n",
       " 'worm',\n",
       " 'of',\n",
       " 'a',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub',\n",
       " '-',\n",
       " 'Sub',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'through',\n",
       " 'the',\n",
       " 'long',\n",
       " 'Vaticans',\n",
       " 'and',\n",
       " 'street',\n",
       " '-',\n",
       " 'stalls',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " ',',\n",
       " 'picking',\n",
       " 'up',\n",
       " 'whatever',\n",
       " 'random',\n",
       " 'allusions',\n",
       " 'to',\n",
       " 'whales',\n",
       " 'he',\n",
       " 'could',\n",
       " 'anyways',\n",
       " 'find',\n",
       " 'in',\n",
       " 'any',\n",
       " 'book',\n",
       " 'whatsoever',\n",
       " ',',\n",
       " 'sacred',\n",
       " 'or',\n",
       " 'profane',\n",
       " '.',\n",
       " 'Therefore',\n",
       " 'you',\n",
       " 'must',\n",
       " 'not',\n",
       " ',',\n",
       " 'in',\n",
       " 'every',\n",
       " 'case',\n",
       " 'at',\n",
       " 'least',\n",
       " ',',\n",
       " 'take',\n",
       " 'the',\n",
       " 'higgledy',\n",
       " '-',\n",
       " 'piggledy',\n",
       " 'whale',\n",
       " 'statements',\n",
       " ',',\n",
       " 'however',\n",
       " 'authentic',\n",
       " ',',\n",
       " 'in',\n",
       " 'these',\n",
       " 'extracts',\n",
       " ',',\n",
       " 'for',\n",
       " 'veritable',\n",
       " 'gospel',\n",
       " 'cetology',\n",
       " '.',\n",
       " 'Far',\n",
       " 'from',\n",
       " 'it',\n",
       " '.',\n",
       " 'As',\n",
       " 'touching',\n",
       " 'the',\n",
       " 'ancient',\n",
       " 'authors',\n",
       " 'generally',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'poets',\n",
       " 'here',\n",
       " 'appearing',\n",
       " ',',\n",
       " 'these',\n",
       " 'extracts',\n",
       " 'are',\n",
       " 'solely',\n",
       " 'valuable',\n",
       " 'or',\n",
       " 'entertaining',\n",
       " ',',\n",
       " 'as',\n",
       " 'affording',\n",
       " 'a',\n",
       " 'glancing',\n",
       " 'bird',\n",
       " \"'\",\n",
       " 's',\n",
       " 'eye',\n",
       " 'view',\n",
       " 'of',\n",
       " 'what',\n",
       " 'has',\n",
       " 'been',\n",
       " 'promiscuously',\n",
       " 'said',\n",
       " ',',\n",
       " 'thought',\n",
       " ',',\n",
       " 'fancied',\n",
       " ',',\n",
       " 'and',\n",
       " 'sung',\n",
       " 'of',\n",
       " 'Leviathan',\n",
       " ',',\n",
       " 'by',\n",
       " 'many',\n",
       " 'nations',\n",
       " 'and',\n",
       " 'generations',\n",
       " ',',\n",
       " 'including',\n",
       " 'our',\n",
       " 'own',\n",
       " '.',\n",
       " 'So',\n",
       " 'fare',\n",
       " 'thee',\n",
       " 'well',\n",
       " ',',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub',\n",
       " '-',\n",
       " 'Sub',\n",
       " ',',\n",
       " 'whose',\n",
       " 'commentator',\n",
       " 'I',\n",
       " 'am',\n",
       " '.',\n",
       " 'Thou',\n",
       " 'belongest',\n",
       " 'to',\n",
       " 'that',\n",
       " 'hopeless',\n",
       " ',',\n",
       " 'sallow',\n",
       " 'tribe',\n",
       " 'which',\n",
       " 'no',\n",
       " 'wine',\n",
       " 'of',\n",
       " 'this',\n",
       " 'world',\n",
       " 'will',\n",
       " 'ever',\n",
       " 'warm',\n",
       " ';',\n",
       " 'and',\n",
       " 'for',\n",
       " 'whom',\n",
       " 'even',\n",
       " 'Pale',\n",
       " 'Sherry',\n",
       " 'would',\n",
       " 'be',\n",
       " 'too',\n",
       " 'rosy',\n",
       " '-',\n",
       " 'strong',\n",
       " ';',\n",
       " 'but',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'one',\n",
       " 'sometimes',\n",
       " 'loves',\n",
       " 'to',\n",
       " 'sit',\n",
       " ',',\n",
       " 'and',\n",
       " 'feel',\n",
       " 'poor',\n",
       " '-',\n",
       " 'devilish',\n",
       " ',',\n",
       " 'too',\n",
       " ';',\n",
       " 'and',\n",
       " 'grow',\n",
       " 'convivial',\n",
       " 'upon',\n",
       " 'tears',\n",
       " ';',\n",
       " 'and',\n",
       " 'say',\n",
       " 'to',\n",
       " 'them',\n",
       " 'bluntly',\n",
       " ',',\n",
       " 'with',\n",
       " 'full',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'empty',\n",
       " 'glasses',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'not',\n",
       " 'altogether',\n",
       " 'unpleasant',\n",
       " 'sadness',\n",
       " '--',\n",
       " 'Give',\n",
       " 'it',\n",
       " 'up',\n",
       " ',',\n",
       " 'Sub',\n",
       " '-',\n",
       " 'Subs',\n",
       " '!',\n",
       " 'For',\n",
       " 'by',\n",
       " 'how',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'pains',\n",
       " 'ye',\n",
       " 'take',\n",
       " 'to',\n",
       " 'please',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'by',\n",
       " 'so',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'shall',\n",
       " 'ye',\n",
       " 'for',\n",
       " 'ever',\n",
       " 'go',\n",
       " 'thankless',\n",
       " '!',\n",
       " 'Would',\n",
       " 'that',\n",
       " 'I',\n",
       " 'could',\n",
       " 'clear',\n",
       " 'out',\n",
       " 'Hampton',\n",
       " 'Court',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Tuileries',\n",
       " 'for',\n",
       " 'ye',\n",
       " '!',\n",
       " 'But',\n",
       " 'gulp',\n",
       " 'down',\n",
       " 'your',\n",
       " 'tears',\n",
       " 'and',\n",
       " 'hie',\n",
       " 'aloft',\n",
       " 'to',\n",
       " 'the',\n",
       " 'royal',\n",
       " '-',\n",
       " 'mast',\n",
       " 'with',\n",
       " 'your',\n",
       " 'hearts',\n",
       " ';',\n",
       " 'for',\n",
       " 'your',\n",
       " 'friends',\n",
       " 'who',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'before',\n",
       " 'are',\n",
       " 'clearing',\n",
       " 'out',\n",
       " 'the',\n",
       " 'seven',\n",
       " '-',\n",
       " 'storied',\n",
       " 'heavens',\n",
       " ',',\n",
       " 'and',\n",
       " 'making',\n",
       " 'refugees',\n",
       " 'of',\n",
       " 'long',\n",
       " '-',\n",
       " 'pampered',\n",
       " 'Gabriel',\n",
       " ',',\n",
       " 'Michael',\n",
       " ',',\n",
       " 'and',\n",
       " 'Raphael',\n",
       " ',',\n",
       " 'against',\n",
       " 'your',\n",
       " 'coming',\n",
       " '.',\n",
       " 'Here',\n",
       " 'ye',\n",
       " 'strike',\n",
       " 'but',\n",
       " 'splintered',\n",
       " 'hearts',\n",
       " 'together',\n",
       " '--',\n",
       " 'there',\n",
       " ',',\n",
       " 'ye',\n",
       " 'shall',\n",
       " 'strike',\n",
       " 'unsplinterable',\n",
       " 'glasses',\n",
       " '!',\n",
       " 'EXTRACTS',\n",
       " '.',\n",
       " '\"',\n",
       " 'And',\n",
       " 'God',\n",
       " 'created',\n",
       " 'great',\n",
       " 'whales',\n",
       " '.\"',\n",
       " '--',\n",
       " 'GENESIS',\n",
       " '.',\n",
       " '\"',\n",
       " 'Leviathan',\n",
       " 'maketh',\n",
       " 'a',\n",
       " 'path',\n",
       " 'to',\n",
       " 'shine',\n",
       " 'after',\n",
       " 'him',\n",
       " ';',\n",
       " 'One',\n",
       " 'would',\n",
       " 'think',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'to',\n",
       " 'be',\n",
       " 'hoary',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JOB',\n",
       " '.',\n",
       " '\"',\n",
       " 'Now',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'had',\n",
       " 'prepared',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fish',\n",
       " 'to',\n",
       " 'swallow',\n",
       " 'up',\n",
       " 'Jonah',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JONAH',\n",
       " '.',\n",
       " '\"',\n",
       " 'There',\n",
       " 'go',\n",
       " 'the',\n",
       " 'ships',\n",
       " ';',\n",
       " 'there',\n",
       " 'is',\n",
       " 'that',\n",
       " 'Leviathan',\n",
       " 'whom',\n",
       " 'thou',\n",
       " 'hast',\n",
       " 'made',\n",
       " 'to',\n",
       " 'play',\n",
       " 'therein',\n",
       " '.\"',\n",
       " '--',\n",
       " 'PSALMS',\n",
       " '.',\n",
       " '\"',\n",
       " 'In',\n",
       " 'that',\n",
       " 'day',\n",
       " ',',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'with',\n",
       " 'his',\n",
       " 'sore',\n",
       " ',',\n",
       " 'and',\n",
       " 'great',\n",
       " ',',\n",
       " 'and',\n",
       " 'strong',\n",
       " 'sword',\n",
       " ',',\n",
       " 'shall',\n",
       " 'punish',\n",
       " 'Leviathan',\n",
       " 'the',\n",
       " 'piercing',\n",
       " 'serpent',\n",
       " ',',\n",
       " 'even',\n",
       " 'Leviathan',\n",
       " 'that',\n",
       " 'crooked',\n",
       " 'serpent',\n",
       " ';',\n",
       " 'and',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'slay',\n",
       " 'the',\n",
       " 'dragon',\n",
       " 'that',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sea',\n",
       " '.\"',\n",
       " '--',\n",
       " 'ISAIAH',\n",
       " '\"',\n",
       " 'And',\n",
       " 'what',\n",
       " 'thing',\n",
       " 'soever',\n",
       " 'besides',\n",
       " 'cometh',\n",
       " 'within',\n",
       " 'the',\n",
       " 'chaos',\n",
       " 'of',\n",
       " 'this',\n",
       " 'monster',\n",
       " \"'\",\n",
       " 's',\n",
       " 'mouth',\n",
       " ',',\n",
       " 'be',\n",
       " 'it',\n",
       " 'beast',\n",
       " ',',\n",
       " 'boat',\n",
       " ',',\n",
       " 'or',\n",
       " 'stone',\n",
       " ',',\n",
       " 'down',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'all',\n",
       " 'incontinently',\n",
       " 'that',\n",
       " 'foul',\n",
       " 'great',\n",
       " 'swallow',\n",
       " 'of',\n",
       " 'his',\n",
       " ',',\n",
       " 'and',\n",
       " 'perisheth',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bottomless',\n",
       " 'gulf',\n",
       " 'of',\n",
       " 'his',\n",
       " 'paunch',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLUTARCH',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'MORALS',\n",
       " '.',\n",
       " '\"',\n",
       " 'The',\n",
       " 'Indian',\n",
       " 'Sea',\n",
       " 'breedeth',\n",
       " 'the',\n",
       " 'most',\n",
       " 'and',\n",
       " 'the',\n",
       " 'biggest',\n",
       " 'fishes',\n",
       " 'that',\n",
       " 'are',\n",
       " ':',\n",
       " 'among',\n",
       " 'which',\n",
       " 'the',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'Whirlpooles',\n",
       " 'called',\n",
       " 'Balaene',\n",
       " ',',\n",
       " 'take',\n",
       " 'up',\n",
       " 'as',\n",
       " 'much',\n",
       " 'in',\n",
       " 'length',\n",
       " 'as',\n",
       " 'four',\n",
       " 'acres',\n",
       " 'or',\n",
       " 'arpens',\n",
       " 'of',\n",
       " 'land',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLINY',\n",
       " '.',\n",
       " '\"',\n",
       " 'Scarcely',\n",
       " 'had',\n",
       " 'we',\n",
       " 'proceeded',\n",
       " 'two',\n",
       " 'days',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'when',\n",
       " 'about',\n",
       " 'sunrise',\n",
       " 'a',\n",
       " 'great',\n",
       " 'many',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'other',\n",
       " 'monsters',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'appeared',\n",
       " '.',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'former',\n",
       " ',',\n",
       " 'one',\n",
       " 'was',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'monstrous',\n",
       " 'size',\n",
       " '.',\n",
       " '...',\n",
       " 'This',\n",
       " 'came',\n",
       " 'towards',\n",
       " 'us',\n",
       " ',',\n",
       " 'open',\n",
       " '-',\n",
       " 'mouthed',\n",
       " ',',\n",
       " 'raising',\n",
       " 'the',\n",
       " 'waves',\n",
       " 'on',\n",
       " 'all',\n",
       " 'sides',\n",
       " ',',\n",
       " 'and',\n",
       " 'beating',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'before',\n",
       " 'him',\n",
       " 'into',\n",
       " 'a',\n",
       " 'foam',\n",
       " '.\"',\n",
       " '--',\n",
       " 'TOOKE',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'LUCIAN',\n",
       " '.',\n",
       " '\"',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " '.\"',\n",
       " '\"',\n",
       " 'He',\n",
       " 'visited',\n",
       " 'this',\n",
       " 'country',\n",
       " 'also',\n",
       " 'with',\n",
       " 'a',\n",
       " 'view',\n",
       " 'of',\n",
       " 'catching',\n",
       " 'horse',\n",
       " '-',\n",
       " 'whales',\n",
       " ',',\n",
       " 'which',\n",
       " 'had',\n",
       " 'bones',\n",
       " 'of',\n",
       " 'very',\n",
       " 'great',\n",
       " 'value',\n",
       " 'for',\n",
       " 'their',\n",
       " 'teeth',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'some',\n",
       " 'to',\n",
       " 'the',\n",
       " 'king',\n",
       " '.',\n",
       " '...',\n",
       " 'The',\n",
       " 'best',\n",
       " 'whales',\n",
       " 'were',\n",
       " 'catched',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'country',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'some',\n",
       " 'were',\n",
       " 'forty',\n",
       " '-',\n",
       " 'eight',\n",
       " ',',\n",
       " 'some',\n",
       " 'fifty',\n",
       " 'yards',\n",
       " 'long',\n",
       " '.',\n",
       " 'He',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = nltk.corpus.gutenberg.words('melville-moby_dick.txt')\n",
    "my_lines_list=[]\n",
    "for line in text_file:\n",
    "    my_lines_list.append(line)\n",
    "my_lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "englishStemmer = SnowballStemmer(\"english\")\n",
    "englishStemmer.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'having'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishStemmer2 = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "englishStemmer2.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corr'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishStemmer = SnowballStemmer(\"spanish\",ignore_stopwords=True)\n",
    "englishStemmer.stem(\"Corriendo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 wa                  \n",
      "running             running             \n",
      "and                 and                 \n",
      "eating              eating              \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 ha                  \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swimming            \n",
      "after               after               \n",
      "playing             playing             \n",
      "long                long                \n",
      "hours               hour                \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations = \"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "        \n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos=\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
